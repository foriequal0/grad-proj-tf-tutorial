{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "\n",
    "# dataset from  http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php\n",
    "# found on  http://deeplearning.net/datasets/\n",
    "\n",
    "dataset_prfix = './data/'\n",
    "dataset_name = 'coil-100'\n",
    "dataset_path = os.path.join(dataset_prfix, dataset_name)\n",
    "\n",
    "url = \"http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-100/coil-100.zip\"\n",
    "N_CLASSES = 100\n",
    "N_CHANNELS = 1\n",
    "\n",
    "def dataset_prepare():\n",
    "    if os.path.exists(dataset_path):\n",
    "        if os.path.isdir(dataset_path):\n",
    "            return\n",
    "        else:\n",
    "            raise Exception(\"{} is not an directory\".format(DIR))\n",
    "    print(dataset_name, \"is not exist, download & unzip\")\n",
    "    \n",
    "    prev_perdeca = 0\n",
    "    def reporthook(chunk_count, max_chunk_size, total_size):\n",
    "        nonlocal prev_perdeca\n",
    "        estimated_size = chunk_count * max_chunk_size\n",
    "        perdeca = int(estimated_size / total_size * 10)\n",
    "        if prev_perdeca != perdeca:\n",
    "            prev_perdeca = perdeca\n",
    "            print(\"download: \", perdeca * 10, \"%\")\n",
    "        \n",
    "    filename, _ = request.urlretrieve(url, reporthook=reporthook)\n",
    "    print(dataset_name, \"is downloaded to\", filename)\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(prefix)\n",
    "    print(dataset_name, \"is decompressed to\", dataset_path)\n",
    "    \n",
    "dataset_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foriequal0/.local/share/virtualenvs/tf-tutorial-pgL6-UTG/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import random\n",
    "\n",
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "\n",
    "def get_image_paths_and_labels():\n",
    "    files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n",
    "    classified = []\n",
    "    pattern = re.compile(r\"obj(?P<label>\\d+)__\\d+.png\")\n",
    "    for file in files:\n",
    "        m = pattern.match(file)\n",
    "        if m is None:\n",
    "            continue\n",
    "        \n",
    "        label = int(m.group('label')) - 1\n",
    "        path = os.path.join(dataset_path, file)\n",
    "        classified.append((label, path))\n",
    "    \n",
    "    random.shuffle(classified)\n",
    "    \n",
    "    slice_at = int(len(classified) * 0.5)\n",
    "    train_image_paths = [path for (_, path) in classified[:slice_at]]\n",
    "    train_labels = [label for (label, _) in classified[:slice_at]]\n",
    "    test_image_paths = [path for (_, path) in classified[slice_at:]]\n",
    "    test_labels = [label for (label, _) in classified[slice_at:]]\n",
    "    \n",
    "    return train_image_paths, train_labels, test_image_paths, test_labels\n",
    "\n",
    "def make_batch(paths, labels, batch_size):\n",
    "    paths = tf.convert_to_tensor(paths, dtype=tf.string)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    \n",
    "    image, label, path = tf.train.slice_input_producer([paths, labels, paths], shuffle=True)\n",
    "    \n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_png(image, channels=N_CHANNELS)\n",
    "    image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = image / 255 * 2 - 1.0\n",
    "    \n",
    "    X, Y, Z = tf.train.batch([image, label, path], \n",
    "                          batch_size=batch_size,\n",
    "                          capacity=batch_size * 8,\n",
    "                          num_threads=4)\n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "dropout = 0.75\n",
    "\n",
    "train_paths, train_labels, test_paths, test_labels = get_image_paths_and_labels()\n",
    "X, Y, _ = make_batch(train_paths, train_labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, n_classes, dropout, reuse, is_training):\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "        \n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "        \n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "        \n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, loss=0.6392, accuracy=0.914\n",
      "Step 200, loss=0.1868, accuracy=0.977\n",
      "Step 300, loss=0.0946, accuracy=0.984\n",
      "Step 400, loss=0.0322, accuracy=1.000\n",
      "Step 500, loss=0.0193, accuracy=1.000\n",
      "Step 600, loss=0.0479, accuracy=1.000\n",
      "Step 700, loss=0.0113, accuracy=1.000\n",
      "Step 800, loss=0.0202, accuracy=1.000\n",
      "Step 900, loss=0.0045, accuracy=1.000\n",
      "Step 1000, loss=0.0216, accuracy=1.000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "logits_train = conv_net(X, N_CLASSES, dropout, reuse=False, is_training=True)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits_train, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "logits_test = conv_net(X, N_CLASSES, dropout, reuse=True, is_training=False)\n",
    "correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.cast(Y, tf.int64))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    try:\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess = sess, coord=coord)\n",
    "\n",
    "        for step in range(1, num_steps+1):\n",
    "            if step % display_step == 0:\n",
    "                _, loss, acc = sess.run([train_op, loss_op, accuracy])\n",
    "                print(\"Step {}, loss={:.4f}, accuracy={:.3f}\".format(step, loss, acc))\n",
    "            else:\n",
    "                # Only run the optimization op (backprop)\n",
    "                sess.run(train_op)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "        print(\"Optimization Finished!\")\n",
    "        saver.save(sess, './model/coil-100')\n",
    "    except Exception as e:\n",
    "        print(\"Optimization Failed!\")\n",
    "        coord.request_stop(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/coil-100\n",
      "accuracy: 1.0\n",
      "./data/coil-100/obj40__115.png is classified as 40\n",
      "./data/coil-100/obj59__325.png is classified as 59\n",
      "./data/coil-100/obj50__295.png is classified as 50\n",
      "./data/coil-100/obj51__120.png is classified as 51\n",
      "./data/coil-100/obj51__230.png is classified as 51\n",
      "./data/coil-100/obj84__110.png is classified as 84\n",
      "./data/coil-100/obj86__85.png is classified as 86\n",
      "./data/coil-100/obj58__325.png is classified as 58\n",
      "./data/coil-100/obj11__225.png is classified as 11\n",
      "./data/coil-100/obj37__325.png is classified as 37\n",
      "./data/coil-100/obj36__255.png is classified as 36\n",
      "./data/coil-100/obj73__135.png is classified as 73\n",
      "./data/coil-100/obj19__160.png is classified as 19\n",
      "./data/coil-100/obj64__265.png is classified as 64\n",
      "./data/coil-100/obj48__50.png is classified as 48\n",
      "./data/coil-100/obj70__115.png is classified as 70\n"
     ]
    }
   ],
   "source": [
    "Xt, Yt, Zt = make_batch(test_paths, test_labels, 16)\n",
    "logits_test = conv_net(Xt, N_CLASSES, dropout, reuse=True, is_training=False)\n",
    "correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.cast(Yt, tf.int64))\n",
    "test_accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "pred = tf.argmax(logits_test, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, './model/coil-100')\n",
    "    try:\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess = sess, coord=coord)\n",
    "\n",
    "        real_path, pred_label, acc = sess.run([Zt, pred, test_accuracy])\n",
    "        \n",
    "        print(\"accuracy:\", acc)\n",
    "        for i in range(len(real_path)):\n",
    "            print(real_path[i].decode(\"utf-8\"), \"is classified as\", pred_label[i]+1)\n",
    "        \n",
    "        # 이미지를 출력해봐야하는데 귀찮다.\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    except Exception as e:\n",
    "        print(\"Prediction Failed!\")\n",
    "        coord.request_stop(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
